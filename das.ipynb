{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58936dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import pyvene as pv\n",
    "from pyvene import CausalModel\n",
    "from pyvene.models.mlp.modelings_mlp import MLPConfig\n",
    "from pyvene import create_mlp_classifier\n",
    "from pyvene import (\n",
    "    IntervenableModel,\n",
    "    VanillaIntervention,\n",
    "    RotatedSpaceIntervention,\n",
    "    BoundlessRotatedSpaceIntervention,\n",
    "    LowRankRotatedSpaceIntervention,\n",
    "    RepresentationConfig,\n",
    "    IntervenableConfig,\n",
    ")\n",
    "\n",
    "\n",
    "from model_analyzer import ModelAnalyzer\n",
    "from activation_extraction import (\n",
    "    ActivationRecord,\n",
    "    save_activations,\n",
    "    load_activations,\n",
    "    compare_activations,\n",
    "    get_activation_statistics\n",
    ")\n",
    "from intervention import (\n",
    "    InterventionHandler,\n",
    "    ActivationPatch,\n",
    "    SteeringVector,\n",
    "    create_steering_vector as _create_steering_vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e50989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ModelAnalyzer for ..\\models\\Llama-3.2-1B\n",
      "Device: cuda\n",
      "[OK] ModelAnalyzer ready\n",
      "Loading model from ..\\models\\Llama-3.2-1B...\n",
      "Set _attn_implementation to eager in config\n",
      "Set attn_implementation to eager in model\n",
      "[OK] Model loaded on cuda\n",
      "Set attn_implementation to eager in model\n",
      "[OK] Model loaded on cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "analyzer = ModelAnalyzer(\"../models/Llama-3.2-1B\", device=device)\n",
    "analyzer.load_model()\n",
    "\n",
    "tokenizer = analyzer.tokenizer\n",
    "model = analyzer.model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63f7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricing_tag_game_example_sampler(\n",
    "    tokenizer,\n",
    "    amount,\n",
    "    lower_bound,\n",
    "    bound_width,\n",
    "):\n",
    "    (\n",
    "        lower_bound_sample,\n",
    "        upper_bound_sample,\n",
    "        amount_sample,\n",
    "    ) = pricing_tag_game_config_sampler(amount, lower_bound, bound_width)\n",
    "\n",
    "    print(lower_bound_sample, upper_bound_sample, amount_sample)\n",
    "    lower_bound_str = \"%.2f\" % lower_bound_sample\n",
    "    upper_bound_str = \"%.2f\" % upper_bound_sample\n",
    "    if amount_sample >= float(lower_bound_str) and amount_sample <= float(\n",
    "        upper_bound_str\n",
    "    ):\n",
    "        label = tokenizer.convert_tokens_to_ids(\"Yes\")\n",
    "    else:\n",
    "        label = tokenizer.convert_tokens_to_ids(\"No\")\n",
    "\n",
    "    amount_str = \"%.2f dollars\" % amount_sample\n",
    "    instruction = f\"Please say yes only if it costs between {lower_bound_str} and {upper_bound_str} dollars, otherwise no.\"\n",
    "    alpaca_prompt = f\"{instruction}, {amount_str}\"\n",
    "    input_ids = tokenizer(alpaca_prompt, return_tensors=\"pt\").input_ids[0]\n",
    "    output_ids = (torch.ones(input_ids.shape[0]) * -100).long().tolist()\n",
    "    output_ids[-1] = label\n",
    "    input_ids = input_ids.tolist()\n",
    "    #assert len(input_ids) == 82\n",
    "    print(alpaca_prompt, \"fdsfadsf\", label)\n",
    "    print(input_ids, output_ids)\n",
    "\n",
    "    return input_ids, output_ids\n",
    "\n",
    "def custom_sampler():\n",
    "    a = random.randint(10, 29)\n",
    "    b = random.randint(10, 29)\n",
    "    prompt = f\"{a} + {b} = \"\n",
    "    answer = a + b\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids[0]\n",
    "    output_ids = (torch.ones(input_ids.shape[0]) * -100).long().tolist()\n",
    "    output_ids[-1] = tokenizer.convert_tokens_to_ids(f\"{answer}\")\n",
    "\n",
    "    return input_ids, output_ids\n",
    "\n",
    "\n",
    "def factual_sampler(\n",
    "    tokenizer,\n",
    "    max_n_training_examples,\n",
    "):\n",
    "    all_input_ids = []\n",
    "    all_output_ids = []\n",
    "    for _ in range(max_n_training_examples):\n",
    "        input_ids, output_ids = custom_sampler()\n",
    "        \n",
    "        all_input_ids += [input_ids]\n",
    "        all_output_ids += [output_ids]\n",
    "\n",
    "    return all_input_ids, all_output_ids\n",
    "\n",
    "\n",
    "raw_prealign = factual_sampler(tokenizer, 500)\n",
    "prealign_dataset = Dataset.from_dict(\n",
    "    {\"input_ids\": raw_prealign[0], \"labels\": raw_prealign[1]}\n",
    ")\n",
    "prealign_dataset.set_format(\"torch\", columns=[\"input_ids\", \"labels\"])\n",
    "prealign_dataloader = DataLoader(prealign_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2293a245",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m total_count = \u001b[32m0\u001b[39m\n\u001b[32m      2\u001b[39m correct_count = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m.no_grad():\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(prealign_dataloader)):\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs.items():\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "correct_count = 0\n",
    "with torch.no_grad():\n",
    "    for step, inputs in enumerate(tqdm(prealign_dataloader)):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(device)\n",
    "\n",
    "        # aligning forward!\n",
    "        outputs = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            labels=inputs[\"labels\"],\n",
    "        )\n",
    "\n",
    "        actual_test_labels = inputs[\"labels\"][:, -1]\n",
    "        pred_test_labels = torch.argmax(outputs.logits[:, -1], dim=-1)\n",
    "\n",
    "        #print(tokenizer.decode(tokens for tokens in inputs[\"input_ids\"]))\n",
    "        #for i, tokens in enumerate(inputs[\"input_ids\"]):\n",
    "            #print(tokenizer.decode(tokens))\n",
    "            #print(tokenizer.decode(pred_test_labels[i]))\n",
    "\n",
    "        correct_labels = actual_test_labels == pred_test_labels\n",
    "\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "\n",
    "current_acc = round(correct_count / total_count, 2)\n",
    "print(f\"[WARNING: THIS NEEDS TO BE GOOD!] prealign task accuracy: {current_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f544bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(prealign_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94fdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv.set_seed(0)\n",
    "\n",
    "\n",
    "def sample_with_region(region, lower_bound_sample, upper_bound_sample):\n",
    "    if region == 1:\n",
    "        amount_sample = round(random.uniform(0.01, lower_bound_sample - 0.01), 2)\n",
    "    elif region == 2:\n",
    "        amount_sample = round(random.uniform(lower_bound_sample, upper_bound_sample), 2)\n",
    "    elif region == 3:\n",
    "        amount_sample = round(random.uniform(upper_bound_sample + 0.01, 9.99), 2)\n",
    "    return amount_sample\n",
    "\n",
    "\n",
    "def lower_bound_alignment_example_sampler(\n",
    "    tokenizer, amount=None, lower_bound=None, bound_width=None\n",
    "):\n",
    "    (\n",
    "        base_lower_bound_sample,\n",
    "        base_upper_bound_sample,\n",
    "        _,\n",
    "    ) = pricing_tag_game_config_sampler(amount, lower_bound, bound_width)\n",
    "    (\n",
    "        source_lower_bound_sample,\n",
    "        source_upper_bound_sample,\n",
    "        _,\n",
    "    ) = pricing_tag_game_config_sampler(amount, lower_bound, bound_width)\n",
    "\n",
    "    ctf_label_str = random.choice([\"Yes\", \"No\"])\n",
    "    if ctf_label_str == \"Yes\":\n",
    "        ctf_label = tokenizer.convert_tokens_to_ids(\"Yes\")\n",
    "        base_source_regions = [\n",
    "            [1, 2],\n",
    "            [1, 3],\n",
    "            [2, 2],\n",
    "            [2, 3],\n",
    "        ]\n",
    "    elif ctf_label_str == \"No\":\n",
    "        ctf_label = tokenizer.convert_tokens_to_ids(\"No\")\n",
    "        base_source_regions = [[1, 1], [2, 1], [3, 1], [3, 2], [3, 3]]\n",
    "    base_source_region = random.choice(base_source_regions)\n",
    "    base_region = base_source_region[0]\n",
    "    source_region = base_source_region[1]\n",
    "\n",
    "    base_amount_sample = sample_with_region(\n",
    "        base_region, base_lower_bound_sample, base_upper_bound_sample\n",
    "    )\n",
    "    source_amount_sample = sample_with_region(\n",
    "        source_region, source_lower_bound_sample, source_upper_bound_sample\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        base_lower_bound_sample,\n",
    "        base_upper_bound_sample,\n",
    "        source_lower_bound_sample,\n",
    "        source_upper_bound_sample,\n",
    "        base_amount_sample,\n",
    "        source_amount_sample,\n",
    "        ctf_label,\n",
    "        ctf_label_str,\n",
    "    )\n",
    "def pricing_tag_game_config_sampler(amount, lower_bound, bound_width):\n",
    "    if bound_width == None:\n",
    "        bound_width_sample = round(random.uniform(2.50, 7.50), 2)\n",
    "    else:\n",
    "        bound_width_sample = bound_width\n",
    "    if lower_bound == None:\n",
    "        lower_bound_sample = round(random.uniform(0.05, 9.95 - bound_width_sample), 2)\n",
    "        # left a little room to cover corner cases.\n",
    "    else:\n",
    "        lower_bound_sample = lower_bound\n",
    "    upper_bound_sample = bound_width_sample + lower_bound_sample\n",
    "    if amount == None:\n",
    "        amount_sample = round(random.uniform(0.01, 9.99), 2)\n",
    "    else:\n",
    "        amount_sample = amount\n",
    "\n",
    "    return lower_bound_sample, upper_bound_sample, amount_sample\n",
    "\n",
    "def bound_alignment_sampler(\n",
    "    tokenizer,\n",
    "    max_n_training_examples,\n",
    "    bound_functors,\n",
    "    amount=None,\n",
    "    lower_bound=None,\n",
    "    bound_width=None,\n",
    "):\n",
    "    all_base_input_ids = []\n",
    "    all_source_input_ids = []\n",
    "    all_ctf_output_ids = []  # this one does not have input ids, etc..\n",
    "    all_intervention_ids = []\n",
    "\n",
    "    for _ in range(max_n_training_examples):\n",
    "        bound_functor = random.choice(bound_functors)\n",
    "        (\n",
    "            base_lower_bound_sample,\n",
    "            base_upper_bound_sample,\n",
    "            source_lower_bound_sample,\n",
    "            source_upper_bound_sample,\n",
    "            base_amount_sample,\n",
    "            source_amount_sample,\n",
    "            ctf_label,\n",
    "            ctf_label_str,\n",
    "        ) = bound_functor(\n",
    "            tokenizer,\n",
    "            amount,\n",
    "            lower_bound,\n",
    "            bound_width,\n",
    "        )\n",
    "\n",
    "        base_amount_str = \"%.2f dollars\" % base_amount_sample\n",
    "        source_amount_str = \"%.2f dollars\" % source_amount_sample\n",
    "        base_lower_bound_str = \"%.2f\" % base_lower_bound_sample\n",
    "        base_upper_bound_str = \"%.2f\" % base_upper_bound_sample\n",
    "        source_lower_bound_str = \"%.2f\" % source_lower_bound_sample\n",
    "        source_upper_bound_str = \"%.2f\" % source_upper_bound_sample\n",
    "\n",
    "        print(f\"base: [{base_lower_bound_str}, {base_upper_bound_str}], {base_amount_str}\")\n",
    "        print(f\"source: [{source_lower_bound_str}, {source_upper_bound_str}], {source_amount_str}\")\n",
    "        print(f\"ctf label: {ctf_label_str}\")\n",
    "\n",
    "        base_instruction = f\"Please say yes only if it costs between {base_lower_bound_str} and {base_upper_bound_str} dollars, otherwise no.\"\n",
    "        source_instruction = f\"Please say yes only if it costs between {source_lower_bound_str} and {source_upper_bound_str} dollars, otherwise no.\"\n",
    "\n",
    "        #base_alpaca_prompt = alpaca_prompt_template % (\n",
    "            #base_instruction,\n",
    "            #base_amount_str,\n",
    "        #)\n",
    "        #source_alpaca_prompt = alpaca_prompt_template % (\n",
    "            #source_instruction,\n",
    "            #source_amount_str,\n",
    "        #)\n",
    "        base_alpaca_prompt = f\"Please say yes only if it costs between {base_lower_bound_str} and {base_upper_bound_str} dollars, otherwise no. {base_amount_str}\"\n",
    "        source_alpaca_prompt = f\"Please say yes only if it costs between {source_lower_bound_str} and {source_upper_bound_str} dollars, otherwise no. {source_amount_str}\"\n",
    "\n",
    "        base_input_ids = tokenizer(base_alpaca_prompt, return_tensors=\"pt\").input_ids[0]\n",
    "        source_input_ids = tokenizer(\n",
    "            source_alpaca_prompt, return_tensors=\"pt\"\n",
    "        ).input_ids[0]\n",
    "        base_input_ids = base_input_ids.tolist()\n",
    "        source_input_ids = source_input_ids.tolist()\n",
    "        ctf_output_ids = (torch.ones(len(base_input_ids)) * -100).long().tolist()\n",
    "        ctf_output_ids[-1] = ctf_label\n",
    "        intervention_id = 0 if bound_functor == bound_functors[0] else 1\n",
    "\n",
    "        print(bound_functor, bound_functors)\n",
    "        print(intervention_id)\n",
    "\n",
    "        all_base_input_ids += [base_input_ids]\n",
    "        all_source_input_ids += [source_input_ids]\n",
    "\n",
    "        all_ctf_output_ids += [ctf_output_ids]\n",
    "        all_intervention_ids += [intervention_id]\n",
    "\n",
    "        #assert len(base_input_ids) == 82\n",
    "        #assert len(source_input_ids) == 82\n",
    "\n",
    "    return (\n",
    "        all_base_input_ids,\n",
    "        all_source_input_ids,\n",
    "        all_ctf_output_ids,\n",
    "        all_intervention_ids,\n",
    "    )\n",
    "\n",
    "\n",
    "def custom_sampler(\n",
    "    tokenizer,\n",
    "    max_n_training_examples,\n",
    "):\n",
    "    all_base_input_ids = []\n",
    "    all_source_input_ids = []\n",
    "    all_ctf_output_ids = []\n",
    "    all_intervention_ids = []\n",
    "\n",
    "    for _ in range(max_n_training_examples):\n",
    "        base_a, base_b = random.randint(10, 29), random.randint(10, 29)\n",
    "        source_a, source_b = random.randint(10, 29), random.randint(10, 29)\n",
    "        \n",
    "        base_prompt = f\"{base_a} + {base_b} = \"\n",
    "        source_prompt = f\"{source_a} + {source_b} = \"\n",
    "        \n",
    "        base_answer = base_a + base_b\n",
    "        source_answer = source_a + source_b\n",
    "        \n",
    "        base_input_ids = tokenizer(base_prompt, return_tensors=\"pt\").input_ids[0].tolist()\n",
    "        source_input_ids = tokenizer(source_prompt, return_tensors=\"pt\").input_ids[0].tolist()\n",
    "        \n",
    "        #base_output_ids = (torch.ones(base_input_ids.shape[0]) * -100).long().tolist()\n",
    "        #source_output_ids = (torch.ones(source_input_ids.shape[0]) * -100).long().tolist()\n",
    "        \n",
    "        #base_output_ids[-1] = tokenizer.convert_tokens_to_ids(f\"{base_answer}\")\n",
    "        #source_output_ids[-1] = tokenizer.convert_tokens_to_ids(f\"{source_answer}\")\n",
    "\n",
    "\n",
    "\n",
    "        ctf_output_ids = (torch.ones(len(base_input_ids)) * -100).long().tolist()\n",
    "        ctf_output_ids[-1] = tokenizer.convert_tokens_to_ids(f\"{source_answer}\")\n",
    "\n",
    "        intervention_id = 0\n",
    "\n",
    "\n",
    "        #print(f\"base: {base_prompt}{base_answer}\")\n",
    "        #print(f\"source: {source_prompt}{source_answer}\")\n",
    "        #print(f\"ctf label: {source_answer}\")\n",
    "\n",
    "\n",
    "\n",
    "        all_base_input_ids += [base_input_ids]\n",
    "        all_source_input_ids += [source_input_ids]\n",
    "\n",
    "        all_ctf_output_ids += [ctf_output_ids]\n",
    "        all_intervention_ids += [intervention_id]\n",
    "\n",
    "    return (\n",
    "        all_base_input_ids,\n",
    "        all_source_input_ids,\n",
    "        all_ctf_output_ids,\n",
    "        all_intervention_ids,\n",
    "    )\n",
    "\n",
    "###################\n",
    "# data loaders\n",
    "###################\n",
    "#raw_data = bound_alignment_sampler(\n",
    "    #tokenizer, 1, [lower_bound_alignment_example_sampler]\n",
    "#)\n",
    "raw_data = custom_sampler(\n",
    "    tokenizer, 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d638cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_train = (\n",
    "    raw_data[0][:8000],\n",
    "    raw_data[1][:8000],\n",
    "    raw_data[2][:8000],\n",
    "    raw_data[3][:8000],\n",
    ")\n",
    "raw_eval = (\n",
    "    raw_data[0][8000:9000],\n",
    "    raw_data[1][8000:9000],\n",
    "    raw_data[2][8000:9000],\n",
    "    raw_data[3][8000:9000],\n",
    ")\n",
    "raw_test = (\n",
    "    raw_data[0][9000:],\n",
    "    raw_data[1][9000:],\n",
    "    raw_data[2][9000:],\n",
    "    raw_data[3][9000:],\n",
    ")\n",
    "train_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_train[0],\n",
    "        \"source_input_ids\": raw_train[1],\n",
    "        \"labels\": raw_train[2],\n",
    "        \"intervention_ids\": raw_train[3],  # we will not use this field\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    ")\n",
    "eval_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_eval[0],\n",
    "        \"source_input_ids\": raw_eval[1],\n",
    "        \"labels\": raw_eval[2],\n",
    "        \"intervention_ids\": raw_eval[3],  # we will not use this field\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=16,\n",
    ")\n",
    "test_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"input_ids\": raw_test[0],\n",
    "        \"source_input_ids\": raw_test[1],\n",
    "        \"labels\": raw_test[2],\n",
    "        \"intervention_ids\": raw_test[3],  # we will not use this field\n",
    "    }\n",
    ").with_format(\"torch\")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae370793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking sequence lengths...\n",
      "Base input_ids lengths: min=7, max=7, unique=1\n",
      "Source input_ids lengths: min=7, max=7, unique=1\n",
      "Label lengths: min=7, max=7, unique=1\n",
      "\n",
      "✓ All sequences have matching lengths\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check for sequence length mismatches\n",
    "#print(\"Checking sequence lengths...\")\n",
    "#base_lengths = [len(x) for x in raw_data[0][:100]]\n",
    "#source_lengths = [len(x) for x in raw_data[1][:100]]\n",
    "#label_lengths = [len(x) for x in raw_data[2][:100]]\n",
    "\n",
    "#print(f\"Base input_ids lengths: min={min(base_lengths)}, max={max(base_lengths)}, unique={len(set(base_lengths))}\")\n",
    "#print(f\"Source input_ids lengths: min={min(source_lengths)}, max={max(source_lengths)}, unique={len(set(source_lengths))}\")\n",
    "#print(f\"Label lengths: min={min(label_lengths)}, max={max(label_lengths)}, unique={len(set(label_lengths))}\")\n",
    "\n",
    "## Check for mismatches\n",
    "#mismatches = [(i, len(raw_data[0][i]), len(raw_data[1][i]), len(raw_data[2][i])) \n",
    "              #for i in range(min(100, len(raw_data[0])))\n",
    "              #if len(raw_data[0][i]) != len(raw_data[1][i]) or len(raw_data[0][i]) != len(raw_data[2][i])]\n",
    "#if mismatches:\n",
    "    #print(f\"\\n⚠️ Found {len(mismatches)} mismatches in first 100 samples!\")\n",
    "    #for idx, base_len, source_len, label_len in mismatches[:5]:\n",
    "        #print(f\"  Sample {idx}: base={base_len}, source={source_len}, labels={label_len}\")\n",
    "#else:\n",
    "    #print(\"\\n✓ All sequences have matching lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73a75ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_boundless_das_position_config(model_type, intervention_type, layer):\n",
    "    config = IntervenableConfig(\n",
    "        model_type=model_type,\n",
    "        representations=[\n",
    "            RepresentationConfig(\n",
    "                layer,              # layer\n",
    "                intervention_type,  # intervention type\n",
    "            ),\n",
    "        ],\n",
    "        intervention_types=BoundlessRotatedSpaceIntervention,\n",
    "    )\n",
    "    return config\n",
    "\n",
    "\n",
    "config = simple_boundless_das_position_config(\n",
    "    type(model), \"block_output\", 15\n",
    ")\n",
    "intervenable = IntervenableModel(config, model)\n",
    "intervenable.set_device(\"cuda\")\n",
    "intervenable.disable_model_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ba9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = int(len(train_dataloader) * 3)\n",
    "warm_up_steps = 0.1 * t_total\n",
    "optimizer_params = []\n",
    "for k, v in intervenable.interventions.items():\n",
    "    optimizer_params += [{\"params\": v.rotate_layer.parameters()}]\n",
    "    optimizer_params += [{\"params\": v.intervention_boundaries, \"lr\": 1e-2}]\n",
    "optimizer = torch.optim.Adam(optimizer_params, lr=1e-3)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warm_up_steps, num_training_steps=t_total\n",
    ")\n",
    "\n",
    "\n",
    "# You can define your custom compute_metrics function.\n",
    "def compute_metrics(eval_preds, eval_labels):\n",
    "    total_count = 0\n",
    "    correct_count = 0\n",
    "    for eval_pred, eval_label in zip(eval_preds, eval_labels):\n",
    "        actual_test_labels = eval_label[:, -1]\n",
    "        pred_test_labels = torch.argmax(eval_pred[:, -1], dim=-1)\n",
    "        correct_labels = actual_test_labels == pred_test_labels\n",
    "        total_count += len(correct_labels)\n",
    "        correct_count += correct_labels.sum().tolist()\n",
    "    accuracy = round(correct_count / total_count, 2)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "gradient_accumulation_steps = 4\n",
    "total_step = 0\n",
    "target_total_step = len(train_dataloader) * epochs\n",
    "temperature_start = 50.0\n",
    "temperature_end = 0.1\n",
    "temperature_schedule = (\n",
    "    torch.linspace(temperature_start, temperature_end, target_total_step)\n",
    "    .to(torch.bfloat16)\n",
    "    .to(\"cuda\")\n",
    ")\n",
    "intervenable.set_temperature(temperature_schedule[total_step])\n",
    "\n",
    "\n",
    "def calculate_loss(logits, labels):\n",
    "    shift_logits = logits[..., :, :].contiguous()\n",
    "    shift_labels = labels[..., :].contiguous()\n",
    "    # Flatten the tokens\n",
    "    loss_fct = torch.nn.CrossEntropyLoss()\n",
    "    shift_logits = shift_logits.view(-1, intervenable.model_config.vocab_size)\n",
    "    shift_labels = shift_labels.view(-1)\n",
    "    # Enable model parallelism\n",
    "    shift_labels = shift_labels.to(shift_logits.device)\n",
    "    loss = loss_fct(shift_logits, shift_labels)\n",
    "\n",
    "    for k, v in intervenable.interventions.items():\n",
    "        boundary_loss = 1.0 * v.intervention_boundaries.sum()\n",
    "    loss += boundary_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "335df1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128000, 1187, 489, 220, 777, 284, 220]\n",
      "['<|begin_of_text|>', '24', 'Ġ+', 'Ġ', '19', 'Ġ=', 'Ġ']\n",
      "[128000, 4331]\n",
      "['<|begin_of_text|>', '53']\n",
      "llama trainable parameters:  0\n"
     ]
    }
   ],
   "source": [
    "sample_prompt = tokenizer(\"24 + 19 = \", return_tensors=\"pt\")\n",
    "print(sample_prompt.input_ids[0].tolist())\n",
    "print(tokenizer.convert_ids_to_tokens(sample_prompt.input_ids[0].tolist()))\n",
    "\n",
    "sample_answer = tokenizer(f\"{53}\", return_tensors=\"pt\")\n",
    "print(sample_answer.input_ids[0].tolist())\n",
    "print(tokenizer.convert_ids_to_tokens(sample_answer.input_ids[0].tolist()))\n",
    "\n",
    "#print(model)\n",
    "#print(intervenable.model)\n",
    "print(\"llama trainable parameters: \", pv.count_parameters(intervenable.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f9c0efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama trainable parameters:  0\n",
      "intervention trainable parameters:  4194306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|          | 0/500 [00:13<?, ?it/s, loss=0.28, acc=1]\n",
      "Epoch: 0:   0%|          | 0/500 [00:13<?, ?it/s, loss=0.28, acc=1]\n",
      "Epoch:   0%|          | 0/3 [00:13<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1500 is out of bounds for dimension 0 with size 1500",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m         scheduler.step()\n\u001b[32m     37\u001b[39m         intervenable.set_zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         intervenable.set_temperature(\u001b[43mtemperature_schedule\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtotal_step\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     39\u001b[39m total_step += \u001b[32m1\u001b[39m\n",
      "\u001b[31mIndexError\u001b[39m: index 1500 is out of bounds for dimension 0 with size 1500"
     ]
    }
   ],
   "source": [
    "intervenable.model.train()  # train enables drop-off but no grads\n",
    "print(\"llama trainable parameters: \", pv.count_parameters(intervenable.model))\n",
    "print(\"intervention trainable parameters: \", intervenable.count_parameters())\n",
    "train_iterator = trange(0, int(epochs), desc=\"Epoch\")\n",
    "for epoch in train_iterator:\n",
    "    epoch_iterator = tqdm(\n",
    "        train_dataloader, desc=f\"Epoch: {epoch}\", position=0, leave=True\n",
    "    )\n",
    "    for step, inputs in enumerate(epoch_iterator):\n",
    "        for k, v in inputs.items():\n",
    "            #print(v)\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                # v = torch.zeros(v.shape).to(device)\n",
    "                inputs[k] = v.to(device)\n",
    "        b_s = inputs[\"input_ids\"].shape[0]\n",
    "        _, counterfactual_outputs = intervenable(\n",
    "            {\"input_ids\": inputs[\"input_ids\"]},\n",
    "            [{\"input_ids\": inputs[\"source_input_ids\"]}],\n",
    "            {\"sources->base\": 6},  # swap 5th token\n",
    "        )\n",
    "        eval_metrics = compute_metrics(\n",
    "            [counterfactual_outputs.logits], [inputs[\"labels\"]]\n",
    "        )\n",
    "\n",
    "        # loss and backprop\n",
    "        loss = calculate_loss(counterfactual_outputs.logits, inputs[\"labels\"])\n",
    "        loss_str = round(loss.item(), 2)\n",
    "        epoch_iterator.set_postfix({\"loss\": loss_str, \"acc\": eval_metrics[\"accuracy\"]})\n",
    "\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        if total_step % gradient_accumulation_steps == 0:\n",
    "            if not (gradient_accumulation_steps > 1 and total_step == 0):\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                intervenable.set_zero_grad()\n",
    "                intervenable.set_temperature(temperature_schedule[total_step])\n",
    "        total_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on the test set\n",
    "eval_labels = []\n",
    "eval_preds = []\n",
    "with torch.no_grad():\n",
    "    epoch_iterator = tqdm(test_dataloader, desc=f\"Test\")\n",
    "    for step, inputs in enumerate(epoch_iterator):\n",
    "        for k, v in inputs.items():\n",
    "            if v is not None and isinstance(v, torch.Tensor):\n",
    "                inputs[k] = v.to(\"cuda\")\n",
    "        b_s = inputs[\"input_ids\"].shape[0]\n",
    "        _, counterfactual_outputs = intervenable(\n",
    "            {\"input_ids\": inputs[\"input_ids\"]},\n",
    "            [{\"input_ids\": inputs[\"source_input_ids\"]}],\n",
    "            {\"sources->base\": 6},  # swap 80th token\n",
    "        )\n",
    "        eval_labels += [inputs[\"labels\"]]\n",
    "        eval_preds += [counterfactual_outputs.logits]\n",
    "eval_metrics = compute_metrics(eval_preds, eval_labels)\n",
    "print(eval_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech_interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
